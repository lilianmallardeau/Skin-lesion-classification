{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The role of segmentation in skin lesion classification using an ISIC dataset\n",
    "*Lilian MALLARDEAU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.rcParams['figure.dpi'] = 150\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.applications import EfficientNetB0 as EfficientNet\n",
    "\n",
    "from utils import *\n",
    "from notifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "csv_file = \"dataset/ISIC_2020_Training_GroundTruth_v2.csv\"\n",
    "duplicates_csv_file = \"dataset/ISIC_2020_Training_Duplicates.csv\"\n",
    "images_folder = \"dataset/train_jpeg/\"\n",
    "\n",
    "dataset_size = 20\n",
    "epochs = 300\n",
    "batch_size = 256\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "notifier = TelegramNotifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(csv_file)\n",
    "duplicates = list(pd.read_csv(duplicates_csv_file)['image_name_2'])\n",
    "\n",
    "# Removing duplicates\n",
    "metadata.drop(metadata[metadata['image_name'].map(lambda x: x in duplicates)].index, inplace=True)\n",
    "metadata.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    img = cv2.imread(filename)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def load_images(filenames):\n",
    "    return [load_image(filename) for filename in filenames]\n",
    "\n",
    "def resize_image(image):\n",
    "    return cv2.resize(image, input_shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign = metadata[metadata['benign_malignant'] == 'benign']\n",
    "malignant = metadata[metadata['benign_malignant'] == 'malignant']\n",
    "\n",
    "sample = metadata.sample(dataset_size)\n",
    "\n",
    "notifier.send_message(\"Loading images...\")\n",
    "train_images = load_images(\"dataset/train_jpeg/\" + sample['image_name'] + \".jpg\")\n",
    "train_labels = sample['target']\n",
    "\n",
    "notifier.send_message(\"Resizing images...\")\n",
    "train_images_resized = np.empty((dataset_size, *input_shape))\n",
    "for i, img in enumerate(train_images):\n",
    "    train_images_resized[i] = resize_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifacts removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures_grid(\n",
    "    [\n",
    "        (train_images_resized[0], \"Original image\"),\n",
    "        (apply_morpho_closing(train_images_resized[0]), \"Image with morphological closing applied\"),\n",
    "    ],\n",
    "    layout=(1, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = [apply_morpho_closing(img) for img in train_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unvignetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unvignette(img):\n",
    "    w, h = img.shape[:2]\n",
    "    new_img = img.copy()\n",
    "    kernel_x = cv2.getGaussianKernel(w, 150)\n",
    "    kernel_y = cv2.getGaussianKernel(h, 150)\n",
    "    kernel = kernel_y * kernel_x.T\n",
    "    mask = 255 * kernel / np.linalg.norm(kernel)\n",
    "    for i in range(3):\n",
    "        new_img[:, :, i] = new_img[:, :, i] / mask.T\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_morpho_closing(train_images[0], 6)\n",
    "pictures_grid(\n",
    "    [\n",
    "        (img, \"Original image\"),\n",
    "        (kmeans_mask(img, return_rgb=True), \"Mask\"),\n",
    "        (kmeans_segmentation(img), \"Segmented image\"),\n",
    "    ],\n",
    "    layout=(1, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_segmented = [kmeans_segmentation(img) for img in train_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Chan-Vese algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chanvese_mask(img, extended_output=False):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    mask = skimage.segmentation.chan_vese(img_gray, mu=.25, lambda1=1, lambda2=1, tol=1e-3, max_iter=200, dt=0.5, init_level_set=\"checkerboard\", extended_output=extended_output)\n",
    "    return mask\n",
    "\n",
    "def chanvese_segmentation(img):\n",
    "    mask = chanvese_mask(img)\n",
    "    segmented_image = img.copy()\n",
    "    segmented_image[mask] = 255\n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures_grid(\n",
    "    [\n",
    "        (train_images[0], \"Original image\"),\n",
    "        (chanvese_segmentation(train_images[0]), \"Chan-Vese segmentation\"),\n",
    "    ],\n",
    "    layout=(1, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "for malignant pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    augmented_images = []\n",
    "    vertical_flip = cv2.flip(image, 0)\n",
    "    horizontal_flip = cv2.flip(image, 1)\n",
    "    augmented_images.append(cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE))\n",
    "    augmented_images.append(cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "    augmented_images.append(cv2.rotate(image, cv2.ROTATE_180))\n",
    "    augmented_images.append(vertical_flip)\n",
    "    augmented_images.append(horizontal_flip)\n",
    "    augmented_images.append(cv2.rotate(vertical_flip, cv2.ROTATE_90_CLOCKWISE))\n",
    "    augmented_images.append(cv2.rotate(horizontal_flip, cv2.ROTATE_90_CLOCKWISE))\n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (_, row) in enumerate(sample.iterrows()):\n",
    "    if row['benign_malignant'] == 'malignant':\n",
    "        augmented_images = augment_image(train_images[index])\n",
    "        train_images.extend(augmented_images)\n",
    "        train_labels = train_labels.append(pd.Series([1]*len(augmented_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet = EfficientNet(weights='imagenet', include_top=False, input_shape=input_shape, classes=2)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(efficientnet)\n",
    "model.add(keras.layers.GlobalAveragePooling2D())\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "# Early stopping to monitor the validation loss and avoid overfitting\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "\n",
    "# Reducing learning rate on plateau\n",
    "rlrop = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Checkpoint callback\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"checkpoints/checkpoint.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5\",\n",
    "    save_weights_only=False,\n",
    "    monitor='val_binary_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    ")\n",
    "callbacks = [Notify(epochs), early_stop, rlrop, checkpoint]\n",
    "\n",
    "history = model.fit(train_images_resized, train_labels, epochs=epochs, verbose=2, callbacks=callbacks, shuffle=True, class_weight={0:1, 1:10})\n",
    "\n",
    "model.save_weights(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e57eebdd9b1d34d8bcef79fccb3bb8312fa0b1415693d4ea6d5149454a5e28a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
